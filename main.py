import openai
import streamlit as st
import os
from moviepy import *

# Configuration de l'API OpenAI
openai.api_key = os.getenv("OPENAI_API_KEY")

st.title("Video to text AI")
st.write(
    "Welcome! This tool converts video files into text using OpenAI's Whisper model, "
    "and then generates a structured document. Simpply upload a video to get started!"
)

# Initialisation des √©tats
if "transcription" not in st.session_state:
    st.session_state.transcription = None
if "summary" not in st.session_state:
    st.session_state.summary = None


# Fonction pour extraire l'audio d'une vid√©o
def extract_audio_from_video(video_path, output_audio_path):
    video = VideoFileClip(video_path)
    video.audio.write_audiofile(output_audio_path)


# T√©l√©chargement du fichier vid√©o
uploaded_file = st.file_uploader("üì§ Upload your video file", type=["mp4", "mkv", "avi", "mov"])

if uploaded_file:
    # Sauvegarder le fichier t√©l√©charg√© localement
    video_path = f"./uploaded_videos/{uploaded_file.name}"
    os.makedirs("uploaded_videos", exist_ok=True)
    with open(video_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    st.success(f"‚úÖ Uploaded {uploaded_file.name} successfully!")

    # Extraire l'audio du fichier vid√©o
    audio_path = video_path.rsplit(".", 1)[0] + ".mp3"
    st.write("üîä Extracting audio from the video...")
    extract_audio_from_video(video_path, audio_path)
    st.success("‚úÖ Audio extracted successfully!")

    # Transcrire l'audio √† l'aide du mod√®le Whisper
    st.write("üìù Transcribing the audio...")
    try:
        with open(audio_path, "rb") as audio_file:
            transcription = openai.Audio.transcribe(model="whisper-1", file=audio_file)
        st.session_state.transcription = transcription["text"]
        st.success("‚úÖ Transcription completed successfully!")
    except Exception as e:
        st.error(f"‚ùå An error occurred during transcription: {e}")

# Afficher le bouton "G√©n√©rer le r√©sum√©" si la transcription est disponible
if st.session_state.transcription and "summary" not in st.session_state:
    if st.button("üìù Generate Structured Summary"):
        st.write("‚è≥ Generating summary... Please wait.")

        # Demander √† OpenAI de g√©n√©rer un r√©sum√© structur√©
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are an expert at summarizing transcriptions into structured formats."},
                    {"role": "user", "content": f"Summarize the following transcription into a structured format:\n\n{st.session_state.transcription}"}
                ],
                temperature=0.7
            )
            st.session_state.summary = response["choices"][0]["message"]["content"]
            st.success("‚úÖ Summary generated successfully!")
        except Exception as e:
            st.error(f"‚ùå An error occurred during summarization: {e}")

# Afficher le r√©sum√© si disponible
if st.session_state.summary:
    st.write("üìå **Structured Summary:**")
    st.text_area("Summary", st.session_state.summary, height=300)

# Bouton pour r√©initialiser l'application
if st.button("Reset"):
    st.session_state.transcription = None
    st.session_state.summary = None
    st.experimental_rerun()
